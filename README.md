# Document-to-Data Pipeline - Phase 1

**Schema-agnostic document parser** that converts PDFs/images into layout-aware JSON + Markdown with bounding-box citations.

## ğŸ¯ Overview

This pipeline extracts structured information from documents while preserving layout, reading order, and traceability through bounding-box citations. Designed for on-prem, open-source deployment with CPU-first support (GPU optional for later phases).

## âœ¨ Features

- **Document Ingestion**: PDF and image support with preprocessing (de-skew, de-noise, DPI normalization)
- **Layout Segmentation**: Detect text, title, list, table, figure, and form blocks using LayoutParser + heuristic line-density enhancement
- **OCR**: PaddleOCR (primary) and Tesseract (fallback) with word-level bounding boxes
- **Semantic Labeling**: Qwen2.5-7B-Instruct via Ollama for fine-grained role classification
- **Table Processing**: Path A (heuristics) and Path B (Qwen-VL) for structured extraction
- **Figure Processing**: Qwen-VL classification and chart data extraction
- **Interactive Visualization**: Streamlit app with side-by-side document/JSON/Markdown view
- **REST API**: FastAPI endpoints for each pipeline stage
- **Caching**: SHA256-based artifact caching for pipeline efficiency

## ğŸ“ Project Structure

```
doc2data/
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ pipelines/         # Pipeline stages (ingest, segment, ocr, slm_label, assemble)
â”‚   â”œâ”€â”€ processing/        # Pre/post-processing utilities
â”‚   â”œâ”€â”€ ocr/               # OCR modules (PaddleOCR, Tesseract)
â”‚   â””â”€â”€ vlm/               # Vision-language models (Ollama client, Qwen-VL)
â”œâ”€â”€ app/                   # Application interfaces
â”‚   â”œâ”€â”€ api_main.py        # FastAPI REST endpoints
â”‚   â””â”€â”€ streamlit_main.py # Streamlit interactive UI
â”œâ”€â”€ utils/                 # Utility modules (models, config, cache, visualization)
â”œâ”€â”€ data/                  # Data directory
â”‚   â””â”€â”€ sample_docs/       # Sample PDFs for testing
â”œâ”€â”€ models/                # Model weights and download scripts
â”œâ”€â”€ tests/                 # Test suite
â”‚   â””â”€â”€ test_pipeline.py   # Comprehensive integration test
â”œâ”€â”€ eval/                  # Evaluation scripts
â”œâ”€â”€ cache/                 # Artifact cache (gitignored)
â””â”€â”€ validation/            # Validation results
```

## ğŸš€ Setup

### Prerequisites

- **Python 3.10+**
- **Ollama** installed and running (for SLM/VLM inference)
- **Tesseract OCR** installed (`brew install tesseract` on macOS)
- **Virtual environment** (recommended)

### Installation

1. **Clone and navigate:**
```bash
cd doc2data
```

2. **Create virtual environment:**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies:**
```bash
pip install -r requirements.txt
```

4. **Download models** (auto-downloads on first use, or run manually):
```bash
python models/download_models.py
```

5. **Pull Ollama models:**
```bash
ollama pull qwen2.5:7b-instruct
ollama pull qwen2-vl:7b
```

6. **Configure environment** (optional):
```bash
cp .env.example .env
# Edit .env with your settings
```

## ğŸ“Š Current Status

### âœ… Completed (Step 1 & 2)

#### Step 1: Ingest & Preprocess âœ… **PASS (5/5)**
- âœ… PDF/image loading with PyMuPDF/pdf2image
- âœ… DPI normalization (300 DPI default)
- âœ… De-skew using OpenCV Hough transform
- âœ… De-noise using median/Gaussian blur
- âœ… Digital text layer extraction (bypasses OCR when available)
- âœ… Word-level bounding box extraction from digital text

**Status**: Production-ready, fully functional

#### Step 2: Layout Segmentation âœ… **Working (ML Model + Heuristic Fallback)**
- âœ… LayoutParser integration with PaddleDetectionLayoutModel (PubLayNet)
- âœ… Auto-downloads PubLayNet weights (221MB, PPYOLOv2 variant)
- âœ… Works on CPU/MPS (no CUDA required)
- âœ… Box merging with IoU threshold (0.5)
- âœ… Reading order resolution (topâ†’bottom, leftâ†’right, multi-column support)
- âœ… Form region detection via line-density heuristics layered on ML outputs
- âœ… Heuristic fallback (OpenCV contour detection) when ML model unavailable
- âš  Parameter tuning needed for optimal granularity

**Status**: Functional, ML model working, needs parameter tuning for fine-grained detection

### ğŸš§ In Progress

#### Step 3: OCR (per-block)
- âœ… PaddleOCR wrapper with auto-download
- âœ… Tesseract fallback wrapper
- âœ… OCR orchestration pipeline
- âš  Header/footer detection heuristics
- âš  Caption candidate detection
- âš  Text cleaning and post-processing

**Status**: Core functionality implemented, heuristics need refinement

#### Step 4: Semantic Labeling (SLM)
- âœ… Ollama client integration
- âœ… Qwen2.5-7B-Instruct prompt templates
- âš  Semantic role labeling (title, H1/H2, header/footer, page#, list-item, kv-pair hints)
- âš  JSON output parsing and validation

**Status**: Infrastructure ready, labeling logic needs implementation

#### Step 5: Table & Figure Processing
- âœ… Qwen-VL integration scaffolding
- âš  Table extraction (Path A: heuristics, Path B: Qwen-VL)
- âš  Figure classification and chart extraction
- âš  Caption extraction and linking

**Status**: Placeholders implemented, core logic pending

#### Step 6: Assembly
- âœ… Document data models (Block, TableBlock, FigureBlock, Document)
- âš  Hierarchical JSON builder
- âš  Markdown generator with citations
- âš  Bounding-box citation preservation

**Status**: Data models ready, assembly logic pending

### ğŸ“‹ Planned

#### UI & API
- âš  Streamlit UI (file upload, page viewer, JSON/MD tabs, interactive overlays)
- âš  FastAPI endpoints (all pipeline stages)
- âš  Real-time progress updates
- âš  Error handling and validation

#### Testing & Validation
- âœ… Integration test (tests/test_pipeline.py)
- âš  Unit tests for each pipeline stage
- âš  Evaluation scripts (layout validation, OCR validation)
- âš  Performance benchmarks

#### Deployment
- âœ… Dockerfile (CPU-first)
- âœ… docker-compose.yml
- âš  GPU support (NVIDIA DGX integration)
- âš  vLLM integration for GPU-accelerated SLM inference

## ğŸ§ª Testing

### Run Integration Test

Test Steps 1 & 2 (Ingest & Layout Segmentation):

```bash
python tests/test_pipeline.py
```

This will:
- Load sample PDFs from `data/sample_docs/`
- Run ingestion and preprocessing
- Perform layout segmentation
- Display detailed results and evaluation scores

### Expected Output

```
Step 1: 5/5 (PASS)
Step 2: 3-6/6 (Working, needs parameter tuning)
```

## ğŸ“– Usage

### Streamlit App (Coming Soon)

```bash
streamlit run app/streamlit_main.py
```

Open http://localhost:8501 in your browser.

### FastAPI Server (Coming Soon)

```bash
python -m uvicorn app.api_main:app --reload
```

API will be available at http://localhost:8000

### API Endpoints (Planned)

- `POST /ingest` - Ingest document (PDF/image)
- `POST /segment` - Segment layout
- `POST /ocr` - Run OCR
- `POST /label` - Semantic labeling
- `POST /table/process` - Process table
- `POST /figure/process` - Process figure
- `POST /assemble` - Assemble final JSON/Markdown
- `GET /health` - Health check

## ğŸ³ Docker

### Build and Run

```bash
docker-compose up --build
```

This will start:
- API server on port 8000
- Streamlit app on port 8501

**Note**: Ollama should be running on the host (or add to docker-compose.yml).

## ğŸ¯ Milestones

### M1: Ingest + Segment + OCR âœ… **In Progress**
- [x] PDF/image ingestion
- [x] Layout segmentation (ML model + heuristic fallback)
- [x] OCR with PaddleOCR/Tesseract
- [ ] OCR heuristics and validation
- [ ] Target: â‰¥95% text coverage

### M2: SLM Labeling + Assembly ğŸ“‹ **Planned**
- [ ] Semantic role labeling
- [ ] JSON/Markdown assembly
- [ ] Table/Figure basic processing
- [ ] Target: Correct header/footer/KV pair tagging

### M3: Full Demo ğŸ“‹ **Planned**
- [ ] Streamlit UI
- [ ] Docker image
- [ ] Interactive visualization
- [ ] Target: One-click demo working

## ğŸ”§ Configuration

See `.env.example` for configuration options:

- `OLLAMA_HOST`: Ollama server address (default: http://localhost:11434)
- `SLM_MODEL`: SLM model name (default: qwen2.5:7b-instruct)
- `VLM_MODEL`: VLM model name (default: qwen-vl)
- `DPI`: Image resolution (default: 300)
- `DESKEW_ENABLED`: Enable de-skew (default: True)
- `DENOISE_ENABLED`: Enable de-noise (default: True)
- `OCR_PRIMARY`: Primary OCR engine (default: paddleocr)
- `LAYOUT_MODEL_NAME`: Layout model name (default: publaynet)

## ğŸ—ï¸ Architecture

### Pipeline Flow

```
PDF/Image
  â†“
[1] Ingest & Preprocess (de-skew, de-noise, digital text extraction)
  â†“
[2] Layout Segmentation (ML model or heuristic fallback)
  â†“
[3] OCR (per-block, PaddleOCR/Tesseract)
  â†“
[4] Semantic Labeling (SLM via Ollama)
  â†“
[5] Table & Figure Processing (Qwen-VL)
  â†“
[6] Assembly (JSON + Markdown with citations)
  â†“
Document (JSON + Markdown)
```

### Key Design Decisions

1. **CPU-First**: All components work on CPU, with optional GPU acceleration later
2. **Progressive Fallbacks**: ML model â†’ Heuristic â†’ Basic processing
3. **Caching**: SHA256-based caching for pipeline artifacts
4. **Modular**: Each pipeline stage is independent and testable
5. **Traceability**: All extracted data includes bounding-box citations

## ğŸš€ Future Enhancements

### GPU Acceleration
- NVIDIA DGX integration
- vLLM for GPU-accelerated SLM inference
- CUDA-enabled PyTorch for Detectron2 (if needed)

### Model Improvements
- Fine-tune LayoutParser model for better granularity
- Custom SLM prompts for domain-specific labeling
- Advanced table extraction (TATR integration)
- Chart data extraction (Plotly/Matplotlib parsing)

### Features
- Multi-language support
- Batch processing
- Incremental processing
- Webhook notifications
- Export formats (JSON, Markdown, HTML, PDF)

## ğŸ“ Notes

### Detectron2 Alternative
- **PaddleDetectionLayoutModel** is used instead of Detectron2
- Works on CPU/MPS without CUDA
- Auto-downloads PubLayNet weights (221MB)
- No Detectron2 installation required

### Model Downloads
- LayoutParser models auto-download on first use
- PaddleOCR models auto-download on initialization
- Ollama models must be pulled manually (`ollama pull`)

### Performance
- CPU processing: ~5-10 seconds per page
- Heuristic fallback: Faster but less accurate
- ML model: Slower but more accurate
- Caching reduces redundant processing

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Follow the existing code structure
2. Add tests for new features
3. Update documentation
4. Ensure CPU-first compatibility

## ğŸ“„ License

[Your License Here]

## ğŸ™ Acknowledgments

- LayoutParser team for PubLayNet models
- PaddleOCR for OCR capabilities
- Ollama for SLM/VLM hosting
- Qwen team for language models

---

**Status**: ğŸš§ Active Development - Steps 1 & 2 Complete, Steps 3-6 In Progress

**Last Updated**: 2024
